{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Mitigating bias in recommender systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This is an introduction to fairness in recommender systems. A recommender system aims to recommend the best item according to the user preference.\n",
    "\n",
    "A recommender system can be biased in multiple ways. For example, we may be concerned that the items in our database will not get equal representation (item fairness). Alternative, our main concern may be that different groups of users (e.g. male/female users) will get different item recommendations (user fairness). In the following, we will show how to mitigate item fairness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 - Importing modules and loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We will start by importing the example dataset, which should be downloaded from https://www.kaggle.com/code/saurabhbagchi/recommendation-system-on-amazon-electronic-data. This dataset contains user-item interactions. The users are Amazon users and the items are electronics items from the Amazon website. An interaction happens when a user rates a given item, on a scale of 1 to 5. We sample 10K rows from this dataset, because recommender models are notoriously slow to train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install holisticai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Item</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7361996</th>\n",
       "      <td>A33O21HCNI66WV</td>\n",
       "      <td>B00D695GS8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1389571200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202352</th>\n",
       "      <td>A2QHEDGPYLV8PO</td>\n",
       "      <td>B001OS51X8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1292889600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884358</th>\n",
       "      <td>A2C9RVSQ6XS2P8</td>\n",
       "      <td>B002V88HFE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1363996800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6939069</th>\n",
       "      <td>A3EM243NDJ4DF3</td>\n",
       "      <td>B00AQRUW4Q</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1363737600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552038</th>\n",
       "      <td>AVGP3YE61L5ZV</td>\n",
       "      <td>B0071LN0VC</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1354752000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6416017</th>\n",
       "      <td>A3KWVP2L6YIRRR</td>\n",
       "      <td>B008YZ8T92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1355097600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7457640</th>\n",
       "      <td>AYEKDZQN0O7KU</td>\n",
       "      <td>B00DU2CHE2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1397174400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573280</th>\n",
       "      <td>ACCFAWMOAOZPZ</td>\n",
       "      <td>B002EVPCSS</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1360540800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085237</th>\n",
       "      <td>A2MINX5Z8AU40N</td>\n",
       "      <td>B004G08OO4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1389916800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6156318</th>\n",
       "      <td>A2A1DCVITEI1CW</td>\n",
       "      <td>B008BMX1AU</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1385596800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   User        Item  Rating        Time\n",
       "7361996  A33O21HCNI66WV  B00D695GS8     4.0  1389571200\n",
       "2202352  A2QHEDGPYLV8PO  B001OS51X8     1.0  1292889600\n",
       "2884358  A2C9RVSQ6XS2P8  B002V88HFE     5.0  1363996800\n",
       "6939069  A3EM243NDJ4DF3  B00AQRUW4Q     5.0  1363737600\n",
       "5552038   AVGP3YE61L5ZV  B0071LN0VC     4.0  1354752000\n",
       "...                 ...         ...     ...         ...\n",
       "6416017  A3KWVP2L6YIRRR  B008YZ8T92     5.0  1355097600\n",
       "7457640   AYEKDZQN0O7KU  B00DU2CHE2     4.0  1397174400\n",
       "2573280   ACCFAWMOAOZPZ  B002EVPCSS     5.0  1360540800\n",
       "4085237  A2MINX5Z8AU40N  B004G08OO4     2.0  1389916800\n",
       "6156318  A2A1DCVITEI1CW  B008BMX1AU     3.0  1385596800\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\n",
    "from sklearn.datasets import fetch_openml\n",
    "bunch = fetch_openml(data_id='45050')\n",
    "df = bunch['frame']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER TOOLS -- NOTHING TO DO\n",
    "def explode(arr, num_items):\n",
    "    out = np.zeros(num_items)\n",
    "    out[arr] = 1\n",
    "    return out\n",
    "\n",
    "def recommended_items(model_pred, data_matrix, k):\n",
    "    recommended_items_mask = data_matrix>0\n",
    "    candidate_index = ~recommended_items_mask\n",
    "    candidate_rating = model_pred*candidate_index\n",
    "    return np.argsort(-candidate_rating,axis=1)[:,:k]\n",
    "\n",
    "def recommender_rmse(mat_pred, mat_true):\n",
    "    mask = mat_true>0\n",
    "    rmse = np.sqrt(np.sum(np.power(mat_pred-mat_true,2)*mask)/np.sum(mask))\n",
    "    return rmse\n",
    "\n",
    "def recommender_mae(mat_pred, mat_true):\n",
    "    mask = mat_true>0\n",
    "    mae = np.sum(np.abs(mat_pred-mat_true)*mask)/np.sum(mask)\n",
    "    return mae\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Pre-processing the data\n",
    "We pivot the data to an interaction matrix. When we have interaction data in a column format, it is useful to 'pivot' it into an interaction matrix. The rows of this matrix represent the users, the columns represent the items, and each interaction results in a non-NaN entry within the matrix containing the rating. These matrices are usually very sparse, hence the vast majority of entries are NaNs. For simplicity, we replace the NaN values with 0 in the data matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot = df.pivot_table(index='User', columns='Item', values='Rating', aggfunc='mean')\n",
    "user_dict = dict(zip(df_pivot.index, range(len(df_pivot.index))))\n",
    "item_dict = dict(zip(df_pivot.columns, range(len(df_pivot.columns))))\n",
    "data_matrix = np.nan_to_num(df_pivot.to_numpy(), nan=0)\n",
    "data_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Train a Baseline model (Do Not Rerun this section)\n",
    "We use an out of the box NMF model using surprise. NMF is non negative matrix factorization and is a common approach to collaborative filtering. Documentation can be found here : https://surprise.readthedocs.io/en/stable/matrix_factorization.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and load data into surprise\n",
    "from surprise import Reader, Dataset, NMF, accuracy\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[[\"User\",\t\"Item\",\t\"Rating\"]], reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and testsets\n",
    "trainset = data.build_full_trainset()\n",
    "testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.NMF at 0x7fbc5988d040>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model and train it\n",
    "mf = NMF(n_factors = 40, biased=False)\n",
    "mf.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the unknown values\n",
    "predictions = mf.test(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the accuracy metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  1.0346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0346441237569046"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3644577073657274"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the following results:\n",
    "\n",
    "| Metric | Value | Reference |\n",
    "| --- | --- | --- |\n",
    "| RMSE | 1.36| 0 |\n",
    "| MAE | 1.04 | 0 |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the scores, we need to predict the items our system will recommend. We choose a top K approach (with K=50). For each user, we recommend the top K highest scoring items (that are not in the training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = get_top_n(predictions, n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions matrix (top 50 for each user)\n",
    "mat = np.zeros(data_matrix.shape)\n",
    "\n",
    "for key, el in top_n.items():\n",
    "    key_index = user_dict[key]\n",
    "    item_indices = [item_dict[code[0]] for code in el]\n",
    "    mat[key_index,:] = explode(item_indices, data_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the bias metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giuliofilippi/Documents/GitHub/holisticai/tutorials/mitigating_bias_tutorials/../../holisticai/utils/_recommender_tools.py:228: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.sum(np.where(p != 0, p * np.log(p), 0))\n",
      "/Users/giuliofilippi/Documents/GitHub/holisticai/tutorials/mitigating_bias_tutorials/../../holisticai/utils/_recommender_tools.py:228: RuntimeWarning: invalid value encountered in multiply\n",
      "  return -np.sum(np.where(p != 0, p * np.log(p), 0))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aggregate Diversity</th>\n",
       "      <td>0.499058</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GINI index</th>\n",
       "      <td>0.906853</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exposure Distribution Entropy</th>\n",
       "      <td>6.762744</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Recommendation Popularity</th>\n",
       "      <td>1236.795483</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Value Reference\n",
       "Metric                                                  \n",
       "Aggregate Diversity                   0.499058         1\n",
       "GINI index                            0.906853         0\n",
       "Exposure Distribution Entropy         6.762744         -\n",
       "Average Recommendation Popularity  1236.795483         -"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute bias metrics\n",
    "from holisticai.bias.metrics import recommender_bias_metrics\n",
    "recommender_bias_metrics(mat_pred=mat, metric_type='item_based')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the following results:\n",
    "\n",
    "| Metric | Value | Reference |\n",
    "| --- | --- | --- |\n",
    "| Aggregate Diversity | 0.5 | 1 |\n",
    "| Gini Index   | 0.91 | 0 |\n",
    "| Avg Recommendation Pop   | 1237 | - |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Mitigating bias (Inprocessing)\n",
    "We will now show how we can mitigate bias using the holisticai library. More specifically we will focus on item fairness, and use Blind Spot Aware Matrix Factorization.\n",
    "\n",
    "Reference:\n",
    "        Sun, Wenlong, et al. \"Debiasing the human-recommender system\n",
    "        feedback loop in collaborative filtering.\" Companion Proceedings\n",
    "        of The 2019 World Wide Web Conference. 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from holisticai.bias.mitigation import BlindSpotAwareMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>  **Task 1**\n",
    "- **Train a BlindSpotAwareMF model with parameters K=40, beta=30, steps=150, alpha=0.001, lamda=3, verbose=1**\n",
    "<font >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [00:34<00:00,  4.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "mf = BlindSpotAwareMF(K=40, beta=30, steps=150, alpha=0.001, lamda=3, verbose=1)\n",
    "mf.fit(data_matrix)\n",
    "mat_pred = mf.pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommend top 50 scoring items according to our model (that are not in training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_items = recommended_items(mat_pred, data_matrix, 50)\n",
    "new_recs = [explode(new_items[u], len(df_pivot.columns)) for u in range(df_pivot.shape[0])]\n",
    "new_df_pivot_db = pd.DataFrame(new_recs, columns = df_pivot.columns)\n",
    "mat = new_df_pivot_db.replace(0,np.nan).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>  **Task 2**\n",
    "- **Evaluate your Model's efficacy**\n",
    "<font >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.067001936688743"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Efficacy metric\n",
    "# TODO\n",
    "recommender_mae(mf.pred, data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1768928675991843"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender_rmse(mf.pred, data_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the following results:\n",
    "\n",
    "| Metric | Value | Reference |\n",
    "| --- | --- | --- |\n",
    "| RMSE | 1.17| 0 |\n",
    "| MAE | 1.06 | 0 |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>  **Task 3**\n",
    "- **Evaluate your Model's bias**\n",
    "<font >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giuliofilippi/Documents/GitHub/holisticai/tutorials/mitigating_bias_tutorials/../../holisticai/utils/_recommender_tools.py:228: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.sum(np.where(p != 0, p * np.log(p), 0))\n",
      "/Users/giuliofilippi/Documents/GitHub/holisticai/tutorials/mitigating_bias_tutorials/../../holisticai/utils/_recommender_tools.py:228: RuntimeWarning: invalid value encountered in multiply\n",
      "  return -np.sum(np.where(p != 0, p * np.log(p), 0))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aggregate Diversity</th>\n",
       "      <td>0.500062</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GINI index</th>\n",
       "      <td>0.824597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exposure Distribution Entropy</th>\n",
       "      <td>7.483994</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Recommendation Popularity</th>\n",
       "      <td>500.842377</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Value Reference\n",
       "Metric                                                 \n",
       "Aggregate Diversity                  0.500062         1\n",
       "GINI index                           0.824597         0\n",
       "Exposure Distribution Entropy        7.483994         -\n",
       "Average Recommendation Popularity  500.842377         -"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bias metrics\n",
    "# TODO\n",
    "from holisticai.bias.metrics import recommender_bias_metrics\n",
    "recommender_bias_metrics(mat_pred=mat, metric_type='item_based')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the following results:\n",
    "\n",
    "| Metric | Value | Reference |\n",
    "| --- | --- | --- |\n",
    "| Aggregate Diversity | 0.5 | 1 |\n",
    "| Gini Index   | 0.82 | 0 |\n",
    "| Avg Recommendation Pop   | 500| - |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Questions**\n",
    "- **Has efficacy increased or decreased when training with bias mitigation?**\n",
    "- **Has bias increased or decreased when training with bias mitigation?**\n",
    "- Note : Average Recommendation Popularity : average over users of average over items of number of times that item appreas in training set.\n",
    "<font > "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> **Answers**\n",
    "- We notice the efficacy of the inprocessing model is similar to the surprise NMF model, and actually better in terms of RMSE.\n",
    "- Bias has decreased. For instance look at the average recommendation popularity, it has decreased from 1237 to 500 meaning we are recommending more unpopular items.\n",
    "<font > "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('torch-nightly')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Jun  1 2022, 06:36:29) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5fa74478a026ac530ef194e4df855dfb9675779484e20284ae5f690a2266d7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
