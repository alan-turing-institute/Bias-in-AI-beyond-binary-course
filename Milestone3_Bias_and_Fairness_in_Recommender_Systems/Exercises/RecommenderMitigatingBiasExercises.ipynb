{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Mitigating bias in recommender systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This is an introduction to fairness in recommender systems. A recommender system aims to recommend the best item according to the user preference.\n",
    "\n",
    "A recommender system can be biased in multiple ways. For example, we may be concerned that the items in our database will not get equal representation (item fairness). Alternative, our main concern may be that different groups of users (e.g. male/female users) will get different item recommendations (user fairness). In the following, we will show how to mitigate item fairness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 - Importing modules and loading the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We will start by importing the example [dataset](https://www.openml.org/search?type=data&sort=runs&id=45050&status=active), which we host on our library via openml. This dataset contains user-item interactions. The users are Amazon users and the items are electronics items from the Amazon website. An interaction happens when a user rates a given item, on a scale of 1 to 5. We sample 10K rows from this dataset, because recommender models are notoriously slow to train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install holisticai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Item</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AKM1MP6P0OYPR</td>\n",
       "      <td>0132793040</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2CX7LUOHB2NDG</td>\n",
       "      <td>0321732944</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2NWSAGRHCP8N5</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2WNBOD3WNDNKT</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1GI0U4ZRJA8WN</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>A1YY6103EIE3H4</td>\n",
       "      <td>B00000J1F3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>A1NDLPA3KGGPSM</td>\n",
       "      <td>B00000J1F3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>A3QP5ASI0AJJU1</td>\n",
       "      <td>B00000J1F3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>A2AKNCSNUEQKSZ</td>\n",
       "      <td>B00000J1F3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>A2S5HBS56RKQYX</td>\n",
       "      <td>B00000J1F3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                User        Item  Rating\n",
       "0      AKM1MP6P0OYPR  0132793040     5.0\n",
       "1     A2CX7LUOHB2NDG  0321732944     5.0\n",
       "2     A2NWSAGRHCP8N5  0439886341     1.0\n",
       "3     A2WNBOD3WNDNKT  0439886341     3.0\n",
       "4     A1GI0U4ZRJA8WN  0439886341     1.0\n",
       "...              ...         ...     ...\n",
       "9995  A1YY6103EIE3H4  B00000J1F3     5.0\n",
       "9996  A1NDLPA3KGGPSM  B00000J1F3     5.0\n",
       "9997  A3QP5ASI0AJJU1  B00000J1F3     4.0\n",
       "9998  A2AKNCSNUEQKSZ  B00000J1F3     5.0\n",
       "9999  A2S5HBS56RKQYX  B00000J1F3     2.0\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch data from openml\n",
    "from sklearn.datasets import fetch_openml\n",
    "bunch = fetch_openml(data_id='45050')\n",
    "df = bunch['frame']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER TOOLS -- NOTHING TO DO\n",
    "def explode(arr, num_items):\n",
    "    out = np.zeros(num_items)\n",
    "    out[arr] = 1\n",
    "    return out\n",
    "\n",
    "def recommended_items(model_pred, data_matrix, k):\n",
    "    recommended_items_mask = data_matrix>0\n",
    "    candidate_index = ~recommended_items_mask\n",
    "    candidate_rating = model_pred*candidate_index\n",
    "    return np.argsort(-candidate_rating,axis=1)[:,:k]\n",
    "\n",
    "def recommender_rmse(mat_pred, mat_true):\n",
    "    mask = mat_true>0\n",
    "    rmse = np.sqrt(np.sum(np.power(mat_pred-mat_true,2)*mask)/np.sum(mask))\n",
    "    return rmse\n",
    "\n",
    "def recommender_mae(mat_pred, mat_true):\n",
    "    mask = mat_true>0\n",
    "    mae = np.sum(np.abs(mat_pred-mat_true)*mask)/np.sum(mask)\n",
    "    return mae\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Pre-processing the data\n",
    "We pivot the data to an interaction matrix. When we have interaction data in a column format, it is useful to 'pivot' it into an interaction matrix. The rows of this matrix represent the users, the columns represent the items, and each interaction results in a non-NaN entry within the matrix containing the rating. These matrices are usually very sparse, hence the vast majority of entries are NaNs. For simplicity, we replace the NaN values with 0 in the data matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot = df.pivot_table(index='User', columns='Item', values='Rating', aggfunc='mean')\n",
    "user_dict = dict(zip(df_pivot.index, range(len(df_pivot.index))))\n",
    "item_dict = dict(zip(df_pivot.columns, range(len(df_pivot.columns))))\n",
    "data_matrix = np.nan_to_num(df_pivot.to_numpy(), nan=0)\n",
    "data_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Train a Baseline model (Do Not Rerun this section)\n",
    "We use an out of the box NMF model using surprise. NMF is non negative matrix factorization and is a common approach to collaborative filtering. Documentation can be found here : https://surprise.readthedocs.io/en/stable/matrix_factorization.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and load data into surprise\n",
    "from surprise import Reader, Dataset, NMF, accuracy\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[[\"User\",\t\"Item\",\t\"Rating\"]], reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and testsets\n",
    "trainset = data.build_full_trainset()\n",
    "testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.NMF at 0x7fbc5988d040>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model and train it\n",
    "mf = NMF(n_factors = 40, biased=False)\n",
    "mf.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the unknown values\n",
    "predictions = mf.test(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the accuracy metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  1.0346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0346441237569046"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3644577073657274"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the following results:\n",
    "\n",
    "| Metric | Value | Reference |\n",
    "| --- | --- | --- |\n",
    "| RMSE | 1.36| 0 |\n",
    "| MAE | 1.04 | 0 |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the scores, we need to predict the items our system will recommend. We choose a top K approach (with K=50). For each user, we recommend the top K highest scoring items (that are not in the training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = get_top_n(predictions, n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions matrix (top 50 for each user)\n",
    "mat = np.zeros(data_matrix.shape)\n",
    "\n",
    "for key, el in top_n.items():\n",
    "    key_index = user_dict[key]\n",
    "    item_indices = [item_dict[code[0]] for code in el]\n",
    "    mat[key_index,:] = explode(item_indices, data_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the bias metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giuliofilippi/Documents/GitHub/holisticai/tutorials/mitigating_bias_tutorials/../../holisticai/utils/_recommender_tools.py:228: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.sum(np.where(p != 0, p * np.log(p), 0))\n",
      "/Users/giuliofilippi/Documents/GitHub/holisticai/tutorials/mitigating_bias_tutorials/../../holisticai/utils/_recommender_tools.py:228: RuntimeWarning: invalid value encountered in multiply\n",
      "  return -np.sum(np.where(p != 0, p * np.log(p), 0))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aggregate Diversity</th>\n",
       "      <td>0.499058</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GINI index</th>\n",
       "      <td>0.906853</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exposure Distribution Entropy</th>\n",
       "      <td>6.762744</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Recommendation Popularity</th>\n",
       "      <td>1236.795483</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Value Reference\n",
       "Metric                                                  \n",
       "Aggregate Diversity                   0.499058         1\n",
       "GINI index                            0.906853         0\n",
       "Exposure Distribution Entropy         6.762744         -\n",
       "Average Recommendation Popularity  1236.795483         -"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute bias metrics\n",
    "from holisticai.bias.metrics import recommender_bias_metrics\n",
    "recommender_bias_metrics(mat_pred=mat, metric_type='item_based')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the following results:\n",
    "\n",
    "| Metric | Value | Reference |\n",
    "| --- | --- | --- |\n",
    "| Aggregate Diversity | 0.5 | 1 |\n",
    "| Gini Index   | 0.91 | 0 |\n",
    "| Avg Recommendation Pop   | 1237 | - |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Mitigating bias (Inprocessing)\n",
    "We will now show how we can mitigate bias using the holisticai library. More specifically we will focus on item fairness, and use Blind Spot Aware Matrix Factorization.\n",
    "\n",
    "Reference:\n",
    "        Sun, Wenlong, et al. \"Debiasing the human-recommender system\n",
    "        feedback loop in collaborative filtering.\" Companion Proceedings\n",
    "        of The 2019 World Wide Web Conference. 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from holisticai.bias.mitigation import BlindSpotAwareMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>  **Task 1**\n",
    "- **Train a BlindSpotAwareMF model with parameters K=40, beta=30, steps=150, alpha=0.001, lamda=3, verbose=1**\n",
    "<font >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:34<00:00,  4.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "\n",
    "# predictions\n",
    "mat_pred = mf.pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.067001936688743"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Efficacy metric\n",
    "# TODO\n",
    "recommender_mae(mf.pred, data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1768928675991843"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender_rmse(mf.pred, data_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>  **Task 2**\n",
    "- **Evaluate your Model's efficacy**\n",
    "<font >\n",
    "\n",
    "Use `recommender_mae` and `recommender_rmse` functions provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommend top 50 scoring items according to our model (that are not in training set), and format them into an interaction matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_items = recommended_items(mat_pred, data_matrix, 50)\n",
    "new_recs = [explode(new_items[u], len(df_pivot.columns)) for u in range(df_pivot.shape[0])]\n",
    "new_df_pivot_db = pd.DataFrame(new_recs, columns = df_pivot.columns)\n",
    "mat = new_df_pivot_db.replace(0,np.nan).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>  **Task 3**\n",
    "- **Evaluate your Model's bias. Remember to do the analysis on the recommended items (mat).**\n",
    "<font >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias metrics\n",
    "from holisticai.bias.metrics import recommender_bias_metrics\n",
    "# TODO\n",
    "\n",
    "\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the following results:\n",
    "\n",
    "| Metric | Value | Reference |\n",
    "| --- | --- | --- |\n",
    "| Aggregate Diversity | 0.5 | 1 |\n",
    "| Gini Index   | 0.82 | 0 |\n",
    "| Avg Recommendation Pop   | 500| - |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Questions**\n",
    "- **Has efficacy increased or decreased when training with bias mitigation?**\n",
    "- **Has bias increased or decreased when training with bias mitigation?**\n",
    "- Note : Average Recommendation Popularity : average over users of average over items of number of times that item appreas in interaction matrix.\n",
    "<font > "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('torch-nightly')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5fa74478a026ac530ef194e4df855dfb9675779484e20284ae5f690a2266d7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
