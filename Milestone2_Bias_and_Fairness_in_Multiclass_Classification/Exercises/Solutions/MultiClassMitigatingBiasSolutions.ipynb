{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mitigating Bias in a Multiclass Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will mitigate bias in a multiclass classification model. We will create a pipeline to implement bias mitigation techniques at two different stages: Pre-Processing and Post-Processing. All questions and tasks are bolded and in red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 - Importing modules and loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by loading the dataset. For this notebook, we will be using the 'USCrime' from the OpenML Repository and load it directly from the holisticai library. The dataset combines socio-economic data from the 1990 US Census, law enforcement data from the 1990 US LEMAS survey, and crime data from the 1995 FBI UCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: holisticai in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (0.3.0)\n",
      "Requirement already satisfied: seaborn>=0.11.2 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from holisticai) (0.12.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.64.1 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from holisticai) (4.64.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from holisticai) (1.1.0)\n",
      "Requirement already satisfied: cvxopt<2.0.0,>=1.3.0 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from holisticai) (1.3.0)\n",
      "Requirement already satisfied: cvxpy[cbc]<2.0.0,>=1.3.0 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from holisticai) (1.3.0)\n",
      "Requirement already satisfied: osqp>=0.4.1 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from cvxpy[cbc]<2.0.0,>=1.3.0->holisticai) (0.6.2.post8)\n",
      "Requirement already satisfied: setuptools<=64.0.2 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from cvxpy[cbc]<2.0.0,>=1.3.0->holisticai) (64.0.2)\n",
      "Requirement already satisfied: ecos>=2 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from cvxpy[cbc]<2.0.0,>=1.3.0->holisticai) (2.0.12)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from cvxpy[cbc]<2.0.0,>=1.3.0->holisticai) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from cvxpy[cbc]<2.0.0,>=1.3.0->holisticai) (1.10.0)\n",
      "Requirement already satisfied: scs>=1.1.6 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from cvxpy[cbc]<2.0.0,>=1.3.0->holisticai) (3.2.2)\n",
      "Requirement already satisfied: cylp>=0.91.5 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from cvxpy[cbc]<2.0.0,>=1.3.0->holisticai) (0.91.5)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from scikit-learn>=1.0.2->holisticai) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from scikit-learn>=1.0.2->holisticai) (3.1.0)\n",
      "Requirement already satisfied: pandas>=0.25 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from seaborn>=0.11.2->holisticai) (1.5.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from seaborn>=0.11.2->holisticai) (3.6.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->holisticai) (1.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->holisticai) (9.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->holisticai) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->holisticai) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->holisticai) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->holisticai) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->holisticai) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->holisticai) (23.0)\n",
      "Requirement already satisfied: qdldl in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from osqp>=0.4.1->cvxpy[cbc]<2.0.0,>=1.3.0->holisticai) (0.1.5.post3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from pandas>=0.25->seaborn>=0.11.2->holisticai) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/giuliofilippi/opt/anaconda3/envs/clean_environment/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->holisticai) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# make sure you have holisticai library installed\n",
    "!pip install holisticai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import dataset\n",
    "from holisticai.datasets import  load_us_crime\n",
    "\n",
    "# import some bias metrics\n",
    "from holisticai.bias.metrics import multiclass_bias_metrics\n",
    "\n",
    "# efficacy metrics\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# import bias mitigation techniques\n",
    "from holisticai.bias.mitigation import CorrelationRemover\n",
    "from holisticai.bias.mitigation import FairScoreClassifier\n",
    "from holisticai.bias.mitigation import MLDebiaser\n",
    "\n",
    "# import pipeline function\n",
    "from holisticai.pipeline import Pipeline\n",
    "from holisticai.utils.transformers.bias import SensitiveGroups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>communityname</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>...</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Lakewoodcity</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Tukwilacity</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Aberdeentown</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>Willingborotownship</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.0</td>\n",
       "      <td>Bethlehemtownship</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>12.0</td>\n",
       "      <td>TempleTerracecity</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Seasidecity</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.69</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Waterburytown</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Walthamcity</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Ontariocity</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1993 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state        communityname  fold  population  householdsize  \\\n",
       "0       8.0         Lakewoodcity   1.0        0.19           0.33   \n",
       "1      53.0          Tukwilacity   1.0        0.00           0.16   \n",
       "2      24.0         Aberdeentown   1.0        0.00           0.42   \n",
       "3      34.0  Willingborotownship   1.0        0.04           0.77   \n",
       "4      42.0    Bethlehemtownship   1.0        0.01           0.55   \n",
       "...     ...                  ...   ...         ...            ...   \n",
       "1989   12.0    TempleTerracecity  10.0        0.01           0.40   \n",
       "1990    6.0          Seasidecity  10.0        0.05           0.96   \n",
       "1991    9.0        Waterburytown  10.0        0.16           0.37   \n",
       "1992   25.0          Walthamcity  10.0        0.08           0.51   \n",
       "1993    6.0          Ontariocity  10.0        0.20           0.78   \n",
       "\n",
       "      racepctblack  racePctWhite  racePctAsian  racePctHisp  agePct12t21  ...  \\\n",
       "0             0.02          0.90          0.12         0.17         0.34  ...   \n",
       "1             0.12          0.74          0.45         0.07         0.26  ...   \n",
       "2             0.49          0.56          0.17         0.04         0.39  ...   \n",
       "3             1.00          0.08          0.12         0.10         0.51  ...   \n",
       "4             0.02          0.95          0.09         0.05         0.38  ...   \n",
       "...            ...           ...           ...          ...          ...  ...   \n",
       "1989          0.10          0.87          0.12         0.16         0.43  ...   \n",
       "1990          0.46          0.28          0.83         0.32         0.69  ...   \n",
       "1991          0.25          0.69          0.04         0.25         0.35  ...   \n",
       "1992          0.06          0.87          0.22         0.10         0.58  ...   \n",
       "1993          0.14          0.46          0.24         0.77         0.50  ...   \n",
       "\n",
       "      PctForeignBorn  PctBornSameState  PctSameHouse85  PctSameCity85  \\\n",
       "0               0.12              0.42            0.50           0.51   \n",
       "1               0.21              0.50            0.34           0.60   \n",
       "2               0.14              0.49            0.54           0.67   \n",
       "3               0.19              0.30            0.73           0.64   \n",
       "4               0.11              0.72            0.64           0.61   \n",
       "...              ...               ...             ...            ...   \n",
       "1989            0.22              0.28            0.34           0.48   \n",
       "1990            0.53              0.25            0.17           0.10   \n",
       "1991            0.25              0.68            0.61           0.79   \n",
       "1992            0.45              0.64            0.54           0.59   \n",
       "1993            0.68              0.50            0.34           0.35   \n",
       "\n",
       "      PctSameState85  LandArea  PopDens  PctUsePubTrans  LemasPctOfficDrugUn  \\\n",
       "0               0.64      0.12     0.26            0.20                 0.32   \n",
       "1               0.52      0.02     0.12            0.45                 0.00   \n",
       "2               0.56      0.01     0.21            0.02                 0.00   \n",
       "3               0.65      0.02     0.39            0.28                 0.00   \n",
       "4               0.53      0.04     0.09            0.02                 0.00   \n",
       "...              ...       ...      ...             ...                  ...   \n",
       "1989            0.39      0.01     0.28            0.05                 0.00   \n",
       "1990            0.00      0.02     0.37            0.20                 0.00   \n",
       "1991            0.76      0.08     0.32            0.18                 0.91   \n",
       "1992            0.52      0.03     0.38            0.33                 0.22   \n",
       "1993            0.68      0.11     0.30            0.05                 1.00   \n",
       "\n",
       "      ViolentCrimesPerPop  \n",
       "0                    0.20  \n",
       "1                    0.67  \n",
       "2                    0.43  \n",
       "3                    0.12  \n",
       "4                    0.03  \n",
       "...                   ...  \n",
       "1989                 0.09  \n",
       "1990                 0.45  \n",
       "1991                 0.23  \n",
       "1992                 0.19  \n",
       "1993                 0.48  \n",
       "\n",
       "[1993 rows x 104 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_us_crime()\n",
    " \n",
    "df = pd.concat([dataset[\"data\"], dataset[\"target\"]], axis=1)\n",
    "df_clean = df.iloc[\n",
    "    :, [i for i, n in enumerate(df.isna().sum(axis=0).T.values) if n < 1000]\n",
    "]\n",
    "df_clean = df_clean.dropna()\n",
    "\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Pre-processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to prepare the data for the training of a multiclass classfication model. We will use sklearn's logistic regression as our model of choice, and we use its train_test_split function to split our dataset. Note, we do not want to include protected attributes in the training so we will remove any features that contain 'race' and 'age' from the features during training and inference. We also need to create categories for our multiclass problem so we will split the target value into 3 groups using quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the attribute we want to measure bias with respect to and assign group membership\n",
    "gs = ['racePctWhite']\n",
    "group_a = df_clean[\"racePctWhite\"].apply(lambda x: x > 0.5)\n",
    "group_b = 1 - group_a\n",
    "xor_groups = group_a ^ group_b\n",
    "\n",
    "# remove sensitive attributes from the training data\n",
    "cols = [c for c in df_clean.columns if (not c.startswith('race')) and (not c.startswith('age'))]\n",
    "df_clean = df_clean[cols].iloc[:, 3:]\n",
    "df_clean = df_clean[xor_groups]\n",
    "group_a = group_a[xor_groups]\n",
    "group_b = group_b[xor_groups]\n",
    "\n",
    "# standardize data set\n",
    "scalar = StandardScaler()\n",
    "df_t = scalar.fit_transform(df_clean)\n",
    "X = df_t[:, :-1]\n",
    "\n",
    "# convert the target from a float to 5 categorical groups\n",
    "def convert_float_to_categorical(target, nb_classes, numeric_classes=True):\n",
    "    eps = np.finfo(float).eps\n",
    "    if numeric_classes:\n",
    "        labels = list(range(nb_classes))\n",
    "    else:\n",
    "        labels = [f\"Q{c}-Q{c+1}\" for c in range(nb_classes)]\n",
    "    labels_values = np.linspace(0, 1, nb_classes + 1)\n",
    "    v = np.array(target.quantile(labels_values)).squeeze()\n",
    "    v[0], v[-1] = v[0] - eps, v[-1] + eps\n",
    "    y = target.copy()\n",
    "    for (i, c) in enumerate(labels):\n",
    "        y[(target.values >= v[i]) & (target.values < v[i + 1])] = c\n",
    "    return y.astype(np.int32)\n",
    "\n",
    "nb_classes = 3\n",
    "y = convert_float_to_categorical(df_clean.iloc[:, -1], nb_classes=nb_classes)\n",
    "\n",
    "\n",
    "# split the data into training and testing sets\n",
    "data = X, y, group_a, group_b\n",
    "datasets = train_test_split(*data, test_size=0.2)\n",
    "train_data = datasets[::2]\n",
    "test_data = datasets[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficacy metrics table\n",
    "def efficacy_metrics(y_pred, y_true):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    ba = balanced_accuracy_score(y_true, y_pred)\n",
    "    return pd.DataFrame([['Accuracy', acc],['Balanced Accuracy', ba]], columns=['metric', 'value']).set_index('metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Baseline: training a model and measuring bias\n",
    "\n",
    "In this section, we will show how to create a pipeline to house a scaler, the model and mitigation techniques. For this particular task we will train a Logistic Regression model from sklearn and then measure bias using the metrics from the multiclass_bias_metrics function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Max Multiclass Statistical Parity</th>\n",
       "      <td>0.691273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Multiclass Statistical Parity</th>\n",
       "      <td>0.691273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Multiclass Equality of Opportunity</th>\n",
       "      <td>0.478608</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Multiclass Average Odds</th>\n",
       "      <td>0.315913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Multiclass True Positive Difference</th>\n",
       "      <td>0.409163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Multiclass Equality of Opportunity</th>\n",
       "      <td>0.478608</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Multiclass Average Odds</th>\n",
       "      <td>0.315913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Multiclass True Positive Difference</th>\n",
       "      <td>0.409163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Value  Reference\n",
       "Metric                                                       \n",
       "Max Multiclass Statistical Parity         0.691273          0\n",
       "Mean Multiclass Statistical Parity        0.691273          0\n",
       "Max Multiclass Equality of Opportunity    0.478608          0\n",
       "Max Multiclass Average Odds               0.315913          0\n",
       "Max Multiclass True Positive Difference   0.409163          0\n",
       "Mean Multiclass Equality of Opportunity   0.478608          0\n",
       "Mean Multiclass Average Odds              0.315913          0\n",
       "Mean Multiclass True Positive Difference  0.409163          0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create pipeline for model and standardization\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('scalar', StandardScaler()),\n",
    "        (\"model\", LogisticRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# fit the model to the training data\n",
    "X, y, group_a, group_b = train_data\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# make a prediction on the testing data\n",
    "X, y, group_a, group_b = test_data\n",
    "y_pred = pipeline.predict(X)\n",
    "\n",
    "# extract the sensitive groups from the testing data\n",
    "sensgroup = SensitiveGroups()\n",
    "sens = sensgroup.fit_transform(np.stack([group_a,group_b], axis=1), convert_numeric=True)\n",
    "\n",
    "# calculate relevant bias metrics for multiclass\n",
    "df = multiclass_bias_metrics(\n",
    "    sens,\n",
    "    y_pred,\n",
    "    y,\n",
    "    metric_type='both'\n",
    ")\n",
    "y_baseline = y_pred.copy()\n",
    "df_baseline=df.copy()\n",
    "df_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <td>0.682517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      value\n",
       "metric                     \n",
       "Accuracy           0.684211\n",
       "Balanced Accuracy  0.682517"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficacy_metrics(y_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the summary of bias metrics presented above, we can see that there is bias in the model. Statistical parity (max and mean) are the same in this case as we only consider 2 groups. The value of statistical parity (0.72) is very high. Can we mitigate some bias, while preserving good levels of accuracy/balanced accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Implementing mitigation techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following sections, we will implement bias mitigation at two different levels: Pre-Processing and Post-Processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Pre-Processing method for Bias Mitigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a pre-processing technique, we will be using the [Correlation Remover](https://holisticai.readthedocs.io/en/latest/.generated/holisticai.bias.mitigation.CorrelationRemover.html#holisticai.bias.mitigation.CorrelationRemover). The Correlation Remover applies a linear transformation to the non-sensitive feature columns to remove their correlation with the sensitive feature columns while retaining as much information as possible. Note that the lack of correlation does not imply anything about statistical dependence, for instance information about the protected attributes can still be hidden in pairs of features. Therefore, it is expected this to be most appropriate as a preprocessing step for (generalized) linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Max Multiclass Statistical Parity</th>\n",
       "      <td>0.477804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Multiclass Statistical Parity</th>\n",
       "      <td>0.477804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Multiclass Equality of Opportunity</th>\n",
       "      <td>0.375407</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Multiclass Average Odds</th>\n",
       "      <td>0.254802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Multiclass True Positive Difference</th>\n",
       "      <td>0.362099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Multiclass Equality of Opportunity</th>\n",
       "      <td>0.375407</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Multiclass Average Odds</th>\n",
       "      <td>0.254802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Multiclass True Positive Difference</th>\n",
       "      <td>0.362099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Value  Reference\n",
       "Metric                                                       \n",
       "Max Multiclass Statistical Parity         0.477804          0\n",
       "Mean Multiclass Statistical Parity        0.477804          0\n",
       "Max Multiclass Equality of Opportunity    0.375407          0\n",
       "Max Multiclass Average Odds               0.254802          0\n",
       "Max Multiclass True Positive Difference   0.362099          0\n",
       "Mean Multiclass Equality of Opportunity   0.375407          0\n",
       "Mean Multiclass Average Odds              0.254802          0\n",
       "Mean Multiclass True Positive Difference  0.362099          0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the pipeline \n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('scalar', StandardScaler()),\n",
    "        (\"bm_preprocessing\", CorrelationRemover()),\n",
    "        (\"model\", LogisticRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# prepare training data and parameters\n",
    "X, y, group_a, group_b = train_data\n",
    "fit_params = {\n",
    "    \"bm__group_a\": group_a, \n",
    "    \"bm__group_b\": group_b\n",
    "}\n",
    "\n",
    "# apply steps in pipeline\n",
    "pipeline.fit(X, y, **fit_params)\n",
    "\n",
    "\n",
    "# prepare testing data and parameters\n",
    "X, y, group_a, group_b = test_data\n",
    "predict_params = {\n",
    "    \"bm__group_a\": group_a,\n",
    "    \"bm__group_b\": group_b,\n",
    "}\n",
    "\n",
    "# make a prediction and generate metrics\n",
    "y_pred = pipeline.predict(X, **predict_params)\n",
    "\n",
    "sens = sensgroup.transform(np.stack([group_a,group_b], axis=1), convert_numeric=True)\n",
    "\n",
    "df = multiclass_bias_metrics(\n",
    "    sens,\n",
    "    y_pred,\n",
    "    y,\n",
    "    metric_type='both'\n",
    ")\n",
    "\n",
    "y_correm  = y_pred.copy()\n",
    "df_correm =df.copy()\n",
    "df_correm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.676692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <td>0.674810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      value\n",
       "metric                     \n",
       "Accuracy           0.676692\n",
       "Balanced Accuracy  0.674810"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficacy_metrics(y_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Question 1**\n",
    "- **Has bias increased or decreased after adding the Correlation Remover in the pipeline?**\n",
    "- **Has efficacy increased or decreased after adding the Correlation Remover in the pipeline?**\n",
    "<font >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are improvement with respect to the bias metrics, but not huge improvements. Accuracy decreases but very little."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Post-Processing Methods for Bias Mitigation\n",
    "\n",
    "The post-processing technique you will be implementing is the [ML Debiaser](https://holisticai.readthedocs.io/en/latest/.generated/holisticai.bias.mitigation.MLDebiaser.html#holisticai.bias.mitigation.MLDebiaser) (Alabdulmohsin et al, 2021). The algorithm aims to debias predictions w.r.t. the sensitive class in each demographic group. This procedure solves an optimization problem subject to the statistical parity constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Task 1**\n",
    "- **Implement the ML Debiaser post-processing technique (MLDebiaser) using the pipeline method. Generate a summary of bias metrics and efficacy metrics. (Hint: the order of pipeline steps is different than in the pre-processing example.)**\n",
    "<font >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[elapsed time: 00:00:06 | iter:5/5 | primal_residual::4.3141 | dual_residual::0.0317]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Max Multiclass Statistical Parity</th>\n",
       "      <td>0.334715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Multiclass Statistical Parity</th>\n",
       "      <td>0.334715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Multiclass Equality of Opportunity</th>\n",
       "      <td>0.255992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Multiclass Average Odds</th>\n",
       "      <td>0.241725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Multiclass True Positive Difference</th>\n",
       "      <td>0.213271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Multiclass Equality of Opportunity</th>\n",
       "      <td>0.255992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Multiclass Average Odds</th>\n",
       "      <td>0.241725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Multiclass True Positive Difference</th>\n",
       "      <td>0.213271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Value  Reference\n",
       "Metric                                                       \n",
       "Max Multiclass Statistical Parity         0.334715          0\n",
       "Mean Multiclass Statistical Parity        0.334715          0\n",
       "Max Multiclass Equality of Opportunity    0.255992          0\n",
       "Max Multiclass Average Odds               0.241725          0\n",
       "Max Multiclass True Positive Difference   0.213271          0\n",
       "Mean Multiclass Equality of Opportunity   0.255992          0\n",
       "Mean Multiclass Average Odds              0.241725          0\n",
       "Mean Multiclass True Positive Difference  0.213271          0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('scalar', StandardScaler()),\n",
    "        (\"model\", LogisticRegression()),\n",
    "        (\"bm_postprocessing\", MLDebiaser()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X, y, group_a, group_b = train_data\n",
    "fit_params = {\n",
    "    \"bm__group_a\": group_a, \n",
    "    \"bm__group_b\": group_b\n",
    "}\n",
    "\n",
    "pipeline.fit(X, y, **fit_params)\n",
    "\n",
    "X, y, group_a, group_b = test_data\n",
    "predict_params = {\n",
    "    \"bm__group_a\": group_a,\n",
    "    \"bm__group_b\": group_b,\n",
    "}\n",
    "y_pred = pipeline.predict(X, **predict_params)\n",
    "\n",
    "sens = sensgroup.transform(np.stack([group_a,group_b], axis=1), convert_numeric=True)\n",
    "\n",
    "df = multiclass_bias_metrics(\n",
    "    sens,\n",
    "    y_pred,\n",
    "    y,\n",
    "    metric_type='both'\n",
    ")\n",
    "y_mldebiaser  = y_pred.copy()\n",
    "df_mldebiaser = df.copy()\n",
    "df_mldebiaser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.626566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <td>0.628403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      value\n",
       "metric                     \n",
       "Accuracy           0.626566\n",
       "Balanced Accuracy  0.628403"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficacy_metrics(y_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get results similar to:\n",
    "| Metric | Value | Reference |\n",
    "| ---    | ---   | --- |\n",
    "Accuracy\t|0.65\t|1|\n",
    "Balanced Accuracy\t|0.65\t|1|\n",
    "\n",
    "| Metric | Value | Reference |\n",
    "| ---    | ---   | --- |\n",
    "Max Multiclass Statistical Parity\t|0.34\t|0|\n",
    "Mean Multiclass Statistical Parity\t|0.34\t|0|\n",
    "Max Multiclass Equality of Opportunity\t|0.22\t|0|\n",
    "Max Multiclass Average Odds\t|0.14\t|0|\n",
    "Max Multiclass True Positive Difference\t|0.20\t|0|\n",
    "Mean Multiclass Equality of Opportunity\t\t|0.22\t|0|\n",
    "Mean Multiclass Average Odds\t|0.14\t\t|0|\n",
    "Mean Multiclass True Positive Difference\t\t|0.20\t|0|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Final Question**\n",
    "- **Assuming we care most about acheiving Statistical Parity, which seems to be the best mitigation technique? Comment on the efficacy tradeoff (if any) to acheive better bias metrics.**\n",
    "<font >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ML Debiaser seems to be the best. Although we do suffer some decrease in accuracy to acheive these bias metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "f5fa74478a026ac530ef194e4df855dfb9675779484e20284ae5f690a2266d7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
