{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mitigating Bias in a Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we mitigate bias in a regression model. We will create a pipeline to implement bias mitigation techniques from three levels: Pre-Processing, In-Processing, and Post-Processing. All questions and tasks are bolded and in red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 - Importing modules and loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by loading the dataset. For this milestone, we will be using the 'USCrime' from the OpenML Repository and loading it directly from the holisticai library. The dataset combines socio-economic data from the 1990 US Census, law enforcement data from the 1990 US LEMAS survey, and crime data from the 1995 FBI UCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make sure holisticai is installed\n",
    "!pip install holisticai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, max_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import dataset\n",
    "from holisticai.datasets import load_us_crime\n",
    "\n",
    "# import plotting functions\n",
    "from holisticai.bias.plots import histogram_plot\n",
    "from holisticai.bias.plots import group_pie_plot\n",
    "from holisticai.bias.plots import distribution_plot\n",
    "from holisticai.bias.plots import success_rate_curves\n",
    "\n",
    "# import some bias metrics\n",
    "from holisticai.bias.metrics import statistical_parity_regression\n",
    "from holisticai.bias.metrics import disparate_impact_regression\n",
    "from holisticai.bias.metrics import mae_ratio\n",
    "from holisticai.bias.metrics import rmse_ratio\n",
    "from holisticai.bias.metrics import regression_bias_metrics\n",
    "\n",
    "# import bias mitigation techniques\n",
    "from holisticai.bias.mitigation import LearningFairRepresentation\n",
    "from holisticai.bias.mitigation import GridSearchReduction\n",
    "from holisticai.bias.mitigation import CorrelationRemover\n",
    "from holisticai.bias.mitigation import ExponentiatedGradientReduction\n",
    "from holisticai.bias.mitigation import WasserteinBarycenter\n",
    "\n",
    "\n",
    "# import pipeline function\n",
    "from holisticai.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>communityname</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>...</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Lakewoodcity</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Tukwilacity</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Aberdeentown</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>Willingborotownship</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.0</td>\n",
       "      <td>Bethlehemtownship</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>12.0</td>\n",
       "      <td>TempleTerracecity</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Seasidecity</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.69</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Waterburytown</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Walthamcity</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Ontariocity</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1993 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state        communityname  fold  population  householdsize  \\\n",
       "0       8.0         Lakewoodcity   1.0        0.19           0.33   \n",
       "1      53.0          Tukwilacity   1.0        0.00           0.16   \n",
       "2      24.0         Aberdeentown   1.0        0.00           0.42   \n",
       "3      34.0  Willingborotownship   1.0        0.04           0.77   \n",
       "4      42.0    Bethlehemtownship   1.0        0.01           0.55   \n",
       "...     ...                  ...   ...         ...            ...   \n",
       "1989   12.0    TempleTerracecity  10.0        0.01           0.40   \n",
       "1990    6.0          Seasidecity  10.0        0.05           0.96   \n",
       "1991    9.0        Waterburytown  10.0        0.16           0.37   \n",
       "1992   25.0          Walthamcity  10.0        0.08           0.51   \n",
       "1993    6.0          Ontariocity  10.0        0.20           0.78   \n",
       "\n",
       "      racepctblack  racePctWhite  racePctAsian  racePctHisp  agePct12t21  ...  \\\n",
       "0             0.02          0.90          0.12         0.17         0.34  ...   \n",
       "1             0.12          0.74          0.45         0.07         0.26  ...   \n",
       "2             0.49          0.56          0.17         0.04         0.39  ...   \n",
       "3             1.00          0.08          0.12         0.10         0.51  ...   \n",
       "4             0.02          0.95          0.09         0.05         0.38  ...   \n",
       "...            ...           ...           ...          ...          ...  ...   \n",
       "1989          0.10          0.87          0.12         0.16         0.43  ...   \n",
       "1990          0.46          0.28          0.83         0.32         0.69  ...   \n",
       "1991          0.25          0.69          0.04         0.25         0.35  ...   \n",
       "1992          0.06          0.87          0.22         0.10         0.58  ...   \n",
       "1993          0.14          0.46          0.24         0.77         0.50  ...   \n",
       "\n",
       "      PctForeignBorn  PctBornSameState  PctSameHouse85  PctSameCity85  \\\n",
       "0               0.12              0.42            0.50           0.51   \n",
       "1               0.21              0.50            0.34           0.60   \n",
       "2               0.14              0.49            0.54           0.67   \n",
       "3               0.19              0.30            0.73           0.64   \n",
       "4               0.11              0.72            0.64           0.61   \n",
       "...              ...               ...             ...            ...   \n",
       "1989            0.22              0.28            0.34           0.48   \n",
       "1990            0.53              0.25            0.17           0.10   \n",
       "1991            0.25              0.68            0.61           0.79   \n",
       "1992            0.45              0.64            0.54           0.59   \n",
       "1993            0.68              0.50            0.34           0.35   \n",
       "\n",
       "      PctSameState85  LandArea  PopDens  PctUsePubTrans  LemasPctOfficDrugUn  \\\n",
       "0               0.64      0.12     0.26            0.20                 0.32   \n",
       "1               0.52      0.02     0.12            0.45                 0.00   \n",
       "2               0.56      0.01     0.21            0.02                 0.00   \n",
       "3               0.65      0.02     0.39            0.28                 0.00   \n",
       "4               0.53      0.04     0.09            0.02                 0.00   \n",
       "...              ...       ...      ...             ...                  ...   \n",
       "1989            0.39      0.01     0.28            0.05                 0.00   \n",
       "1990            0.00      0.02     0.37            0.20                 0.00   \n",
       "1991            0.76      0.08     0.32            0.18                 0.91   \n",
       "1992            0.52      0.03     0.38            0.33                 0.22   \n",
       "1993            0.68      0.11     0.30            0.05                 1.00   \n",
       "\n",
       "      ViolentCrimesPerPop  \n",
       "0                    0.20  \n",
       "1                    0.67  \n",
       "2                    0.43  \n",
       "3                    0.12  \n",
       "4                    0.03  \n",
       "...                   ...  \n",
       "1989                 0.09  \n",
       "1990                 0.45  \n",
       "1991                 0.23  \n",
       "1992                 0.19  \n",
       "1993                 0.48  \n",
       "\n",
       "[1993 rows x 104 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data set\n",
    "dataset = load_us_crime(return_X_y=False, as_frame=True)\n",
    "df = pd.concat([dataset[\"data\"], dataset[\"target\"]], axis=1)\n",
    "df_clean = df.iloc[:,[i for i,n in enumerate(df.isna().sum(axis=0).T.values) if n<1000]]\n",
    "df_clean = df_clean.dropna()\n",
    "\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Pre-processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the bias measurement notebook, we are going to prepare the data for the training of a regression model. We will use sklearn's linear regression model as our model of choice, and we use its train_test_split function to split our dataset. Note, we do not want to include protected attributes in the training so we will remove any features that contain 'race' and 'age' from the features during training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the attribute we want to measure bias with respect to and assign group membership\n",
    "gs = ['racePctWhite']\n",
    "groups = {}\n",
    "for race in gs:\n",
    "    groups[race] = df_clean[race].apply(lambda x: x>0.5)\n",
    "\n",
    "group_a =  groups[gs[0]]\n",
    "group_b =  1-group_a#groups[gs[1]]\n",
    "xor_groups  = group_a ^ group_b\n",
    "\n",
    "# remove sensitive attributes from the training data\n",
    "cols = [c for c in df_clean.columns if (not c.startswith('race')) and (not c.startswith('age'))]\n",
    "df_clean = df_clean[cols].iloc[:,3:]\n",
    "df_clean = df_clean[xor_groups]\n",
    "group_a = group_a[xor_groups]\n",
    "group_b = group_b[xor_groups]\n",
    "\n",
    "# standardize and split the data \n",
    "scalar = StandardScaler()\n",
    "df_t = scalar.fit_transform(df_clean)\n",
    "X = df_t[:,:-1]\n",
    "y = df_t[:,-1]\n",
    "\n",
    "X_train,X_test,y_train,y_test, group_a_tr, group_a_ts, group_b_tr, group_b_ts = \\\n",
    "    train_test_split(X, y, group_a, group_b, test_size=0.2, random_state=42)\n",
    "train_data = X_train, y_train, group_a_tr, group_b_tr\n",
    "test_data  = X_test, y_test, group_a_ts, group_b_ts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Training the model and measuring bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>  **Task 1**\n",
    "- **Train the model using the linear regression function from sklearn. Once trained, caclulate the Statisical Parity, Disparate Impact, MAE Ratio, and RMSE Ratio each at the $q = 0.8$ quantile.**\n",
    "<font >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Q80   : -0.7038208168642952\n",
      "Disparate Impact Q80     : 0.10067340067340066\n",
      "MAE Ratio Q80            : 0.80922834612527\n",
      "RMSE Ratio Q80           : 0.8501595473301025\n"
     ]
    }
   ],
   "source": [
    "# Train a simple linear regression model\n",
    "LR = LinearRegression()\n",
    "\n",
    "model = LR.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_true  = np.array(y_test)\n",
    "\n",
    "# TODO\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the following results:\n",
    "\n",
    "| Metric | Value | Reference |\n",
    "| --- | --- | --- |\n",
    "| Statistical Parity Q80 | -0.704 | 0 |\n",
    "| Disparate Impact Q80   |  0.101 | 1 |\n",
    "| MAE Ratio Q80          |  0.809 | 1 |\n",
    "| RMSE Ratio Q80         |  0.850 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Implementing mitigation techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following sections, we will implement bias mitigation at three different levels: Pre-Processing, In-Processing, and Post-Processing. To begin, we must create a pipeline to contain the mitigation technique and model itself. First, we will implement a mitigation technique directly, then we will construct a pipeline to hold our model, standardization technique, and mitigation technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct a baseline model to compare the performance of the bias mitigation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Q90</th>\n",
       "      <td>0.016953</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Q80</th>\n",
       "      <td>0.100673</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Q50</th>\n",
       "      <td>0.424518</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Q50</th>\n",
       "      <td>-0.703821</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Disparate Impact Level</th>\n",
       "      <td>-0.825434</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Score Difference</th>\n",
       "      <td>-1.492622</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z Score Difference</th>\n",
       "      <td>-2.465747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Statistical Parity</th>\n",
       "      <td>0.768248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity AUC</th>\n",
       "      <td>0.439341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE Ratio</th>\n",
       "      <td>0.651463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE Ratio Q80</th>\n",
       "      <td>0.850160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE Ratio</th>\n",
       "      <td>0.557317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE Ratio Q80</th>\n",
       "      <td>0.809228</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlation Difference</th>\n",
       "      <td>-0.048799</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Value Reference\n",
       "Metric                                       \n",
       "Disparate Impact Q90       0.016953         1\n",
       "Disparate Impact Q80       0.100673         1\n",
       "Disparate Impact Q50       0.424518         1\n",
       "Statistical Parity Q50    -0.703821         0\n",
       "No Disparate Impact Level -0.825434         -\n",
       "Average Score Difference  -1.492622         0\n",
       "Z Score Difference        -2.465747         0\n",
       "Max Statistical Parity     0.768248         0\n",
       "Statistical Parity AUC     0.439341         0\n",
       "RMSE Ratio                 0.651463         1\n",
       "RMSE Ratio Q80             0.850160         1\n",
       "MAE Ratio                  0.557317         1\n",
       "MAE Ratio Q80              0.809228         1\n",
       "Correlation Difference    -0.048799         0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct a pipeline\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('scalar', StandardScaler()),\n",
    "        (\"model\", LinearRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X, y, group_a, group_b = train_data\n",
    "\n",
    "# fit the training data\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "\n",
    "# make prediciton on the test set\n",
    "X, y, group_a, group_b = test_data\n",
    "\n",
    "y_pred = pipeline.predict(X)\n",
    "\n",
    "df = regression_bias_metrics(\n",
    "    group_a,\n",
    "    group_b,\n",
    "    y_pred,\n",
    "    y,\n",
    "    metric_type='both'\n",
    ")\n",
    "y_baseline = y_pred.copy()\n",
    "df_baseline=df.copy()\n",
    "df_baseline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 - Pre-Processing Methods for Bias Mitigation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with the Pre-processing techniques. Pre-processing operates on the data level and aims to either combat representation bias or historical bias. To deal with unbalanced data sets experiencing representational bias, pre-processing techniques strategically sample to oversample underrepresented groups. To handle historical bias, data sets that reinforce stereotypes of certain groups, pre-processing techniques aim to remove any proxies to or notions of group membership from the data. We will be implementing the Correlation Remover which applies a linear transformation to the non-sensitive feature columns to remove their correlation with the sensitive feature columns while retaining as much information as possible (as measured by the least-squares error). This method will change the original dataset by removing all correlations with sensitive values. Note that the lack of correlation does not imply anything about statistical dependence. Therefore, it is expected this to be most appropriate as a preprocessing step for (generalized) linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Q90</th>\n",
       "      <td>0.209091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Q80</th>\n",
       "      <td>0.219814</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Q50</th>\n",
       "      <td>0.499692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Q50</th>\n",
       "      <td>-0.440975</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Disparate Impact Level</th>\n",
       "      <td>-0.688300</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Score Difference</th>\n",
       "      <td>-0.961278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z Score Difference</th>\n",
       "      <td>-1.380165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Statistical Parity</th>\n",
       "      <td>0.522925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity AUC</th>\n",
       "      <td>0.304540</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE Ratio</th>\n",
       "      <td>0.606421</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE Ratio Q80</th>\n",
       "      <td>0.871283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE Ratio</th>\n",
       "      <td>0.565125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE Ratio Q80</th>\n",
       "      <td>0.961817</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlation Difference</th>\n",
       "      <td>-0.036380</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Value Reference\n",
       "Metric                                       \n",
       "Disparate Impact Q90       0.209091         1\n",
       "Disparate Impact Q80       0.219814         1\n",
       "Disparate Impact Q50       0.499692         1\n",
       "Statistical Parity Q50    -0.440975         0\n",
       "No Disparate Impact Level -0.688300         -\n",
       "Average Score Difference  -0.961278         0\n",
       "Z Score Difference        -1.380165         0\n",
       "Max Statistical Parity     0.522925         0\n",
       "Statistical Parity AUC     0.304540         0\n",
       "RMSE Ratio                 0.606421         1\n",
       "RMSE Ratio Q80             0.871283         1\n",
       "MAE Ratio                  0.565125         1\n",
       "MAE Ratio Q80              0.961817         1\n",
       "Correlation Difference    -0.036380         0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialise algorithm\n",
    "cr = CorrelationRemover()\n",
    "\n",
    "# standard scale the data\n",
    "X_train, y_train, group_a, group_b = train_data\n",
    "scaler1 = StandardScaler()\n",
    "X_train_t = scaler1.fit_transform(X_train)\n",
    "\n",
    "# fit the cr to the standardized data\n",
    "cr.fit(X_train,group_a, group_b)\n",
    "\n",
    "# transform training data\n",
    "X_train, y_train, group_a_train, group_b_train = train_data\n",
    "X_train_t = scaler1.fit_transform(X_train)\n",
    "new_X_train = cr.transform(X_train_t, group_a_train, group_b_train)\n",
    "\n",
    "# transform testing data\n",
    "X_test, y_test, group_a_test, group_b_test = test_data\n",
    "X_test_t = scaler1.fit_transform(X_test)\n",
    "new_X_test = cr.transform(X_test_t, group_a_test, group_b_test)\n",
    "\n",
    "# Fit a model with new data (transformed by cr algorithm)\n",
    "\n",
    "# train the model\n",
    "X, y, group_a, group_b = train_data\n",
    "X = new_X_train\n",
    "scaler2 = StandardScaler()\n",
    "Xt = scaler2.fit_transform(X)\n",
    "model = LinearRegression()\n",
    "model.fit(Xt, y)\n",
    "\n",
    "# test the model \n",
    "X, y, group_a, group_b = test_data\n",
    "X = new_X_test\n",
    "Xt = scaler2.transform(X)\n",
    "y_pred = model.predict(Xt)\n",
    "\n",
    "# get metrics\n",
    "df = regression_bias_metrics(\n",
    "    group_a,\n",
    "    group_b,\n",
    "    y_pred,\n",
    "    y,\n",
    "    metric_type='both'\n",
    ")\n",
    "y_cr = y_pred.copy()\n",
    "df_cr = df.copy()\n",
    "df_cr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the Disparate Impact Q90 and Statistical Parity Q50 metrics, we can see a performance improvement. While there is still a bias against group a, both metrics are closer to their reference value than before."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will implement the same pre-processing technique using the pipeline method. The pipeline allows for a more streamlined approach to training a model and mitigating bias from it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Q90</th>\n",
       "      <td>0.209091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Q80</th>\n",
       "      <td>0.219814</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Q50</th>\n",
       "      <td>0.499692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Q50</th>\n",
       "      <td>-0.440975</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Disparate Impact Level</th>\n",
       "      <td>-0.763841</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Score Difference</th>\n",
       "      <td>-0.943252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z Score Difference</th>\n",
       "      <td>-1.388035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Statistical Parity</th>\n",
       "      <td>0.529644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity AUC</th>\n",
       "      <td>0.305583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE Ratio</th>\n",
       "      <td>0.565712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE Ratio Q80</th>\n",
       "      <td>0.809563</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE Ratio</th>\n",
       "      <td>0.512898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE Ratio Q80</th>\n",
       "      <td>0.886396</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlation Difference</th>\n",
       "      <td>-0.033565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Value Reference\n",
       "Metric                                       \n",
       "Disparate Impact Q90       0.209091         1\n",
       "Disparate Impact Q80       0.219814         1\n",
       "Disparate Impact Q50       0.499692         1\n",
       "Statistical Parity Q50    -0.440975         0\n",
       "No Disparate Impact Level -0.763841         -\n",
       "Average Score Difference  -0.943252         0\n",
       "Z Score Difference        -1.388035         0\n",
       "Max Statistical Parity     0.529644         0\n",
       "Statistical Parity AUC     0.305583         0\n",
       "RMSE Ratio                 0.565712         1\n",
       "RMSE Ratio Q80             0.809563         1\n",
       "MAE Ratio                  0.512898         1\n",
       "MAE Ratio Q80              0.886396         1\n",
       "Correlation Difference    -0.033565         0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the pipeline \n",
    "model = LinearRegression()\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('scalar', StandardScaler()),\n",
    "        (\"bm_preprocessing\", CorrelationRemover()),\n",
    "        (\"model\", model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# prepare training data and parameters\n",
    "X, y, group_a, group_b = train_data\n",
    "fit_params = {\n",
    "    \"bm__group_a\": group_a, \n",
    "    \"bm__group_b\": group_b\n",
    "}\n",
    "\n",
    "# apply steps in pipeline\n",
    "pipeline.fit(X, y, **fit_params)\n",
    "\n",
    "\n",
    "# prepare testing data and parameters\n",
    "X, y, group_a, group_b = test_data\n",
    "predict_params = {\n",
    "    \"bm__group_a\": group_a,\n",
    "    \"bm__group_b\": group_b,\n",
    "}\n",
    "\n",
    "# make a prediction and generate metrics\n",
    "y_pred = pipeline.predict(X, **predict_params)\n",
    "df = regression_bias_metrics(\n",
    "    group_a,\n",
    "    group_b,\n",
    "    y_pred,\n",
    "    y,\n",
    "    metric_type='both'\n",
    ")\n",
    "y_correm  = y_pred.copy()\n",
    "df_correm =df.copy()\n",
    "df_correm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the order of the steps in the pipeline. First, the standard scalar is applied, then the pre-processing method and finally the model. Looking at the table of bias metrics, we get the same results as the previous implementation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 - In-Processing Methods for Bias Mitigation\n",
    "\n",
    "Now that we have implemented pre-processing algorithms, the next step is to take a look at one level deeper, in-processing. In-processing algorithms operate at the algorithmic level and are applied *during* training. Many in-processing algorithms add an optimization constraint to the loss function to enforce fairness, while others aim to remove any indicators of sensitive attributes. We will implement the Exponentiated Gradient Reduction method (Agarwal et al. (2018)), which aims to solve a series of cost-sensitive prediction problems and return the predictor with the lowest error using fair regression constraints. We will use the pipeline method once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Q90</th>\n",
       "      <td>0.069697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Q80</th>\n",
       "      <td>0.125455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Q50</th>\n",
       "      <td>0.434266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Q50</th>\n",
       "      <td>-0.633729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Disparate Impact Level</th>\n",
       "      <td>-0.930456</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Score Difference</th>\n",
       "      <td>-1.463753</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z Score Difference</th>\n",
       "      <td>-1.891108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Statistical Parity</th>\n",
       "      <td>0.643874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity AUC</th>\n",
       "      <td>0.395300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE Ratio</th>\n",
       "      <td>0.759371</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE Ratio Q80</th>\n",
       "      <td>1.065397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE Ratio</th>\n",
       "      <td>0.711956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE Ratio Q80</th>\n",
       "      <td>1.124545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlation Difference</th>\n",
       "      <td>-0.093856</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Value Reference\n",
       "Metric                                       \n",
       "Disparate Impact Q90       0.069697         1\n",
       "Disparate Impact Q80       0.125455         1\n",
       "Disparate Impact Q50       0.434266         1\n",
       "Statistical Parity Q50    -0.633729         0\n",
       "No Disparate Impact Level -0.930456         -\n",
       "Average Score Difference  -1.463753         0\n",
       "Z Score Difference        -1.891108         0\n",
       "Max Statistical Parity     0.643874         0\n",
       "Statistical Parity AUC     0.395300         0\n",
       "RMSE Ratio                 0.759371         1\n",
       "RMSE Ratio Q80             1.065397         1\n",
       "MAE Ratio                  0.711956         1\n",
       "MAE Ratio Q80              1.124545         1\n",
       "Correlation Difference    -0.093856         0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize model and mitigation technique\n",
    "model = LinearRegression()\n",
    "inprocessing_model = ExponentiatedGradientReduction(constraints=\"BoundedGroupLoss\", \n",
    "                                         loss='Square', min_val=-0.1, max_val=1.3, upper_bound=0.001,\n",
    "                                         ).transform_estimator(model)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('scalar', StandardScaler()),\n",
    "        (\"bm_inprocessing\", inprocessing_model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X, y, group_a, group_b = train_data\n",
    "fit_params = {\n",
    "    \"bm__group_a\": group_a, \n",
    "    \"bm__group_b\": group_b\n",
    "}\n",
    "\n",
    "pipeline.fit(X, y, **fit_params)\n",
    "\n",
    "X, y, group_a, group_b = test_data\n",
    "predict_params = {\n",
    "    \"bm__group_a\": group_a,\n",
    "    \"bm__group_b\": group_b,\n",
    "}\n",
    "y_pred = pipeline.predict(X, **predict_params)\n",
    "df = regression_bias_metrics(\n",
    "    group_a,\n",
    "    group_b,\n",
    "    y_pred,\n",
    "    y,\n",
    "    metric_type='both'\n",
    ")\n",
    "y_exp_grad  = y_pred.copy()\n",
    "df_exp_grad =df.copy()\n",
    "df_exp_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 - Post-Processing Methods for Bias Mitigation\n",
    "\n",
    "The final level of bias mitigation we will be looking at is post-processing. Post-processing is applied after training to the outputs of the model. The original data nor the model are modified in any way. The post-processing technique you will be implementing is the Wasserstein Barycenters (Chzhen, Evgenii, et al. 2020). The algorithm aims to find a fair regressor with a demographic parity constraint under the assumption that the sensitive attribute is avail for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Task 2**\n",
    "- **Implement the Wasserstein Barycenter post-processing technique (WassersteinBarycenter) using the pipeline method. Generate a summary of bias metrics and use the summary to comment on the performance of the algorithm. (Hint: the order of pipeline steps is different than in the pre-processing example.)**\n",
    "<font >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Q90</th>\n",
       "      <td>0.985714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Q80</th>\n",
       "      <td>0.906061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Q50</th>\n",
       "      <td>0.863170</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Q50</th>\n",
       "      <td>-0.020422</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Disparate Impact Level</th>\n",
       "      <td>1.021537</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Score Difference</th>\n",
       "      <td>-0.063446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z Score Difference</th>\n",
       "      <td>-0.103833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Statistical Parity</th>\n",
       "      <td>0.112516</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity AUC</th>\n",
       "      <td>0.042851</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE Ratio</th>\n",
       "      <td>0.391934</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE Ratio Q80</th>\n",
       "      <td>0.428850</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE Ratio</th>\n",
       "      <td>0.360770</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE Ratio Q80</th>\n",
       "      <td>0.418453</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlation Difference</th>\n",
       "      <td>-0.023593</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Value Reference\n",
       "Metric                                       \n",
       "Disparate Impact Q90       0.985714         1\n",
       "Disparate Impact Q80       0.906061         1\n",
       "Disparate Impact Q50       0.863170         1\n",
       "Statistical Parity Q50    -0.020422         0\n",
       "No Disparate Impact Level  1.021537         -\n",
       "Average Score Difference  -0.063446         0\n",
       "Z Score Difference        -0.103833         0\n",
       "Max Statistical Parity     0.112516         0\n",
       "Statistical Parity AUC     0.042851         0\n",
       "RMSE Ratio                 0.391934         1\n",
       "RMSE Ratio Q80             0.428850         1\n",
       "MAE Ratio                  0.360770         1\n",
       "MAE Ratio Q80              0.418453         1\n",
       "Correlation Difference    -0.023593         0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "model = LinearRegression()\n",
    "\n",
    "# TODO add (\"bm_postprocessing\", WasserteinBarycenter()) to following pipeline\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('scalar', StandardScaler()),\n",
    "        (\"model\", model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# train data\n",
    "X, y, group_a, group_b = train_data\n",
    "fit_params = {\n",
    "    \"bm__group_a\": group_a, \n",
    "    \"bm__group_b\": group_b\n",
    "}\n",
    "\n",
    "# fitting\n",
    "pipeline.fit(X, y, **fit_params)\n",
    "\n",
    "# test data\n",
    "X, y, group_a, group_b = test_data\n",
    "predict_params = {\n",
    "    \"bm__group_a\": group_a,\n",
    "    \"bm__group_b\": group_b,\n",
    "}\n",
    "\n",
    "# predicting\n",
    "y_pred = pipeline.predict(X, **predict_params)\n",
    "\n",
    "# metrics\n",
    "df = regression_bias_metrics(\n",
    "    group_a,\n",
    "    group_b,\n",
    "    y_pred,\n",
    "    y,\n",
    "    metric_type='both'\n",
    ")\n",
    "y_wb  = y_pred.copy()\n",
    "df_wb =df.copy()\n",
    "df_wb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the following results:\n",
    "\n",
    "| Metric | Value | Reference |\n",
    "| ---    | ---   | --- |\n",
    "Disparate Impact Q90\t|0.985714\t|1|\n",
    "Disparate Impact Q80\t|0.906061\t|1|\n",
    "Disparate Impact Q50\t|0.863170\t|1|\n",
    "Statistical Parity Q50\t|-0.020422\t|0|\n",
    "No Disparate Impact Level\t|1.021537\t|-|\n",
    "Average Score Difference\t|-0.063446\t|0|\n",
    "Z Score Difference\t|-0.103833\t|0|\n",
    "Max Statistical Parity\t|0.112516\t|0|\n",
    "Statistical Parity AUC\t|0.042851\t|0|\n",
    "RMSE Ratio\t|0.391934\t|1|\n",
    "RMSE Ratio Q80\t|0.428850\t|1|\n",
    "MAE Ratio\t|0.360770\t|1|\n",
    "MAE Ratio Q80\t|0.418453\t|1|\n",
    "Correlation Difference\t|-0.023593\t|0|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mpsEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd368a5ef6c8892f6c87c22c8d56888e698af74589d34ad1bd17c3290e3a6a05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
